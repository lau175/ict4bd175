{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnarBOfUd_Ah"
      },
      "source": [
        "from numpy import concatenate\n",
        "from matplotlib import pyplot\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBiiSkhCeBVQ"
      },
      "source": [
        "# convert series to supervised learning\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = DataFrame(data)\n",
        "\tcols, names = list(), list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t\tif i == 0:\n",
        "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
        "\t\telse:\n",
        "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
        "\t# put it all together\n",
        "\tagg = concat(cols, axis=1)\n",
        "\tagg.columns = names\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2C_OAc8eEGR"
      },
      "source": [
        "dataset=pd.read_csv('eplusout_3years.csv')\n",
        "\n",
        "with open('opt_settings.JSON', 'r') as f:\n",
        "        datastore = json.load(f)\n",
        "        \n",
        "opt_units=datastore['opt_units']\n",
        "opt_e=datastore['opt_e']\n",
        "opt_bs=datastore['opt_bs']\n",
        "opt_stamps=datastore['opt_stamps']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do3d9OPMeJXN"
      },
      "source": [
        "# load dataset\n",
        "values=dataset.values\n",
        "# ensure all data is float\n",
        "values = values.astype('float32')\n",
        "# normalize features\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled = scaler.fit_transform(values)\n",
        "# specify the number of features\n",
        "n_features = len(list(dataset.columns)) #number of columns in dataset\n",
        "n_output = 18 # 3hrs\n",
        "n_train_stamps = 2*364*24*6 #2 years\n",
        "# list to store the results\n",
        "results=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R8p7Tc2eLpm"
      },
      "source": [
        "def Reframing(n_stamps, n_output=n_output, scaled=scaled, n_train_stamps = n_train_stamps):\n",
        "\n",
        "  # frame as supervised learning\n",
        "    reframed = series_to_supervised(scaled, n_stamps, n_output)\n",
        "\n",
        "    # split into train and test sets\n",
        "    values = reframed.values\n",
        "    train = values[:n_train_stamps, :]\n",
        "    test = values[n_train_stamps:, :]\n",
        "\n",
        "    # split into input and outputs\n",
        "    n_obs = n_stamps * n_features\n",
        "    train_X, train_y = train[:, :n_obs], train[:, -n_features]\n",
        "    test_X, test_y = test[:, :n_obs], test[:, -n_features]\n",
        "    \n",
        "    # reshape input to be 3D [samples, timesteps, features]\n",
        "    train_X = train_X.reshape((train_X.shape[0], n_stamps, n_features))\n",
        "    test_X = test_X.reshape((test_X.shape[0], n_stamps, n_features))\n",
        "    \n",
        "    return train_X, train_y, test_X, test_y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ncTMNGjePB_"
      },
      "source": [
        "def PlotResult(d, case, dataset=dataset, n_train_stamps = n_train_stamps):\n",
        "\n",
        "  filename=f\"n_stamps{d['n_stamps']}_epochs{d['epochs']}_batchsize{d['batch_size']}_n_units{d['n_units']}\"\n",
        "  history=d['history']\n",
        "  inv_yhat=d['inv_yhat']\n",
        "\n",
        "  # plot history\n",
        "  fig0 = pyplot.figure()\n",
        "  pyplot.plot(history.history['loss'], label='train')\n",
        "  pyplot.plot(history.history['val_loss'], label='test')\n",
        "  pyplot.xlabel('Epoch')\n",
        "  pyplot.ylabel('Loss (MAE)')\n",
        "  pyplot.title('Loss (MAE) for '+ case)\n",
        "  pyplot.legend()\n",
        "  fig0.savefig(filename+'_loss.png', dpi=120)\n",
        "  pyplot.show()\n",
        "\n",
        "  # plot prediction\n",
        "  fig1 = pyplot.figure()\n",
        "  pyplot.plot(dataset['avg_T_in'][n_train_stamps:].values, label='Real')\n",
        "  pyplot.plot(inv_yhat, label='Predicted')\n",
        "  pyplot.legend()\n",
        "  pyplot.xlabel('Timestamp')\n",
        "  pyplot.ylabel('Tin (Â°C)')\n",
        "  pyplot.title(\"Real Tin vs. Predicted Tin for \"+ case)\n",
        "  fig1.savefig(filename+'_results.png', dpi=120)\n",
        "  print(fig1.dpi)\n",
        "  pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvTQIB5beRtX"
      },
      "source": [
        "def ChangeModel(n_units=50, e=10, bs=72, n_stamps=6, n_output=n_output, scaled=scaled, to_reframe=False, *args):\n",
        "  \n",
        "  if to_reframe:\n",
        "    train_X, train_y, test_X, test_y = Reframing(n_stamps)\n",
        "    print('reframed')\n",
        "    \n",
        "  else:\n",
        "    train_X = args[0]\n",
        "    train_y = args[1]\n",
        "    test_X = args[2]\n",
        "    test_y = args[3]\n",
        "\n",
        "\n",
        "  # design network\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(n_units, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "  model.add(Dense(1))\n",
        "  model.compile(loss='mae', optimizer='adam')\n",
        "\n",
        "  # fit network\n",
        "  history = model.fit(train_X, train_y, epochs=e, batch_size=bs, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "  \n",
        "\n",
        "\n",
        "  # make a prediction\n",
        "  yhat = model.predict(test_X)\n",
        "  test_X = test_X.reshape((test_X.shape[0], n_stamps*n_features))\n",
        "  \n",
        "  # invert scaling for forecast\n",
        "  inv_yhat = concatenate((yhat, test_X[:, -(n_features-1):]), axis=1)\n",
        "  inv_yhat = scaler.inverse_transform(inv_yhat)\n",
        "  inv_yhat = inv_yhat[:,0]\n",
        "  \n",
        "  # invert scaling for actual\n",
        "  test_y = test_y.reshape((len(test_y), 1))\n",
        "  inv_y = concatenate((test_y, test_X[:, -(n_features-1):]), axis=1)\n",
        "  inv_y = scaler.inverse_transform(inv_y)\n",
        "  inv_y = inv_y[:,0]\n",
        "  \n",
        "  # calculate RMSE and MAE\n",
        "  rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
        "  mae = mean_absolute_error(inv_y, inv_yhat)\n",
        "  d={'n_units': n_units, 'epochs': e, 'batch_size':bs, 'n_stamps': n_stamps, 'RMSE': rmse, 'MAE': mae, \"history\": history, \"inv_yhat\": inv_yhat}\n",
        "  print('\\n', d)\n",
        "  #print('Test RMSE: %.3f' % rmse)\n",
        "\n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXSwAubLeWG2"
      },
      "source": [
        "# first choice for parameters\n",
        "train_X, train_y, test_X, test_y = Reframing(1)\n",
        "results.append(ChangeModel(n_units=50, e=10, bs=72, n_stamps=1, n_output=n_output, scaled=scaled, to_reframe=False, train_X, train_y, test_X, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHhcE4ESfHqq"
      },
      "source": [
        "# optimal parameters\n",
        "train_X, train_y, test_X, test_y = Reframing(opt_stamps)\n",
        "results.append(ChangeModel(n_units=opt_units, opt_e=10, opt_bs=72, n_stamps=opt_stamps, n_output=n_output, scaled=scaled, to_reframe=False, train_X, train_y, test_X, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVOi8CwKfhBN"
      },
      "source": [
        "# predict value 24hrs later\n",
        "train_X, train_y, test_X, test_y = Reframing(opt_stamps,n_output=144)\n",
        "results.append(ChangeModel(n_units=opt_units, opt_e=10, opt_bs=72, n_stamps=opt_stamps, n_output=144, scaled=scaled, to_reframe=False, train_X, train_y, test_X, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdzxi9sXgFER"
      },
      "source": [
        "# predict value 1 week later\n",
        "train_X, train_y, test_X, test_y = Reframing(opt_stamps,n_output=1008)\n",
        "results.append(ChangeModel(n_units=opt_units, opt_e=10, opt_bs=72, n_stamps=opt_stamps, n_output=1008, scaled=scaled, to_reframe=False, train_X, train_y, test_X, test_y))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}